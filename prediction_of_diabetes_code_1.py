# -*- coding: utf-8 -*-
"""Prediction_of_diabetes_Code-1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vNDLtewNfA8JqD6w2t4WVBODwjIClIaw
"""

#pip install catboost

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import seaborn as sns

from catboost import CatBoostRegressor
from lightgbm import LGBMClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.exceptions import ConvergenceWarning
from sklearn.linear_model import LogisticRegression, Ridge, Lasso, ElasticNet
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import RobustScaler,LabelEncoder
from sklearn.metrics import roc_auc_score,roc_curve, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV

import warnings
warnings.filterwarnings('ignore')

from google.colab import drive
drive.mount('/content/gdrive')

"""**Pandas Configuration**"""

pd.set_option('display.max_columns', None)
pd.set_option('display.width', 500)
pd.set_option('display.float_format',  '{:.2f}'.format)

"""**Data set investigation**"""

#dfOriginal = pd.read_csv('gdrive/My Drive/Colab Notebooks/Diabetics-project/diabetes.csv')
dfOriginal = pd.read_csv('gdrive/My Drive/Colab Notebooks/Diabetics-project/diabetes-dataset.csv')
df = dfOriginal.copy()
df.describe().T

df.info()

def getDfProperties(data, head=5):
    print("\n Data frame Shape ")
    print(f'Shape     : {df.shape}\n'
          f'Size      : {df.size}\n'
          f'Dimension : {df.ndim}')
    print("\n\n Data Types ")
    print(data.dtypes)
    print("\n\n Head ")
    print(data.head(head))
    print("\n\n Tail ")
    print(data.tail(head))
    print("\n\n Random Sampling ")
    print(data.sample(head))
    print("\n \n Missing Values ")
    print(data.isnull().sum())
    print("\n \n Unique Values ")
    print(data.nunique())
    print("\n\n Describe ")
    print(data.describe().T)
    print("\n Duplicated Values ")
    print(data.duplicated().sum())

getDfProperties(df)

def getColNames(dataframe, cat_th=10, car_th=20, print_results=True):
  cat_cols = [col for col in dataframe.columns if str(dataframe[col].dtypes) in ["category", "object", "bool"]]
  num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < 10 and dataframe[col].dtypes in ["int", "flaot"]]
  cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > 20 and str(dataframe[col].dtypes) in ["category", "object"]]
  cat_cols = [col for col in cat_cols if col not in cat_but_car]
  cat_cols = cat_cols + num_but_cat
  num_cols = [col for col in dataframe.columns if dataframe[col].dtypes in ["int", "float"]]
  num_cols = [col for col in num_cols if col not in cat_cols]

  if print_results:
      print(f'Observations {dataframe.shape[0]}')
      print(f'Variables:  {dataframe.shape[1]}')
      print(f'cat_cols:  {len(cat_cols)}')
      print(f'num_cols:  {len(num_cols)}')
      print(f'cat_but_car:  {len(cat_but_car)}')
      print(f'num_but_cat:  {len(num_but_cat)}')

  return cat_cols, num_cols, cat_but_car

cat_cols, num_cols, cat_but_car = getColNames(df)

def missingValueCheck(dataframe, na_name=False):
    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]
    n_miss = dataframe[na_columns].isnull().sum().sort_values(ascending=False)
    ratio = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)
    missing_df = pd.concat([n_miss, np.round(ratio, 2)], axis=1, keys=['n_miss', 'ratio'])
    print(missing_df, end="\n")

    if na_name:
        return na_columns

missingValueCheck(df)

df[df['BMI'] < 12]

missingValueCols = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]

for col in missingValueCols:
    print(col, df.loc[df[col] == 0].shape[0])
    df[col] = np.where(df[col] == 0, np.nan, df[col])

missingValueCheck(df)

df = df.fillna(df.groupby('Outcome').transform('median'))

def getOutlierThresholds(dataframe, variable, low_quantile=0.10, up_quantile=0.90):
    quantile_one = dataframe[variable].quantile(low_quantile)
    quantile_three = dataframe[variable].quantile(up_quantile)
    interquantile_range = quantile_three - quantile_one
    up_limit = quantile_three + 1.5 * interquantile_range
    low_limit = quantile_one - 1.5 * interquantile_range
    return  low_limit, up_limit

def checkOutlier(dataframe, col_name):
    low_limit, up_limit = getOutlierThresholds(dataframe, col_name)
    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):
        return True
    else:
        return False

def drawOutliers(dataframe,title):
    a = 2
    b = 4
    c = 1
    results = []
    colors=[]

    palette_set3 = sns.color_palette("Set3",len(num_cols))
    for color in palette_set3.as_hex():
        colors.append(color)
    colour_num_cols = zip(num_cols, colors)

    fig = plt.figure(figsize = (20, 10))
    for col, color in colour_num_cols:
        plt.subplot(a, b, c)
        sns.boxplot(dataframe[col], color=color)
        plt.xlabel(f'{dataframe[col].name}', size=15)
        c = c + 1
        results.append(checkOutlier(dataframe, col))
        plt.suptitle(title, size=18);

    plt.tight_layout()
    plt.subplots_adjust(hspace=0.25)
    plt.show()

"""**CORRELATION**"""

corr = df[num_cols].corr()
sns.heatmap(corr, cmap="Blues", annot=True);

def featureExtraction(dataframe):
    dataframe['Insulin_CAT'] = pd.cut(x=dataframe['Insulin'],
                                      bins=[0, 140, 199, np.inf],
                                      labels=["Normal", "Prediabetes", "Diabetes"])

    dataframe['BloodPressure_CAT'] = pd.cut(x=dataframe['BloodPressure'],
                                            bins=[0, 60, 80, 90, 120, np.inf],
                                            labels=["Low_Blood_Pressure", "Normal",
                                                    "Prehypertension", "Hypertension",
                                                    "Hypertensive_Crisis"])

    dataframe['Glucose_CAT'] = pd.cut(x=dataframe['Glucose'],
                                      bins=[0, 140, 199, np.inf],
                                      labels=["Normal", "Impaired_Glucose_Tolerance",
                                              "Diabetes"])

    dataframe['BMI_CAT'] = pd.cut(x=dataframe['BMI'],
                                  bins=[0, 18.5, 24.9, 29.9, 34.9, 39.9,  np.inf],
                                  labels=["Underweight", "Healthy", "Overweight",
                                          "Obese_Class1", "Obese_Class2", "Obese_Class3"])

    dataframe['Age_CAT'] = pd.cut(x=dataframe['Age'],
                                  bins=[20, 40, 60, np.inf],
                                  labels=["Adult", "Middle_Age_Adult", "Senior_Adult"])

    dataframe.loc[(dataframe['Age'] > 40)
                  & (dataframe['BloodPressure_CAT'] == 'Hypertension')
                  & ((dataframe["BMI_CAT"] == "Overweight")
                     | (dataframe["BMI_CAT"] == "Obese_Class1")
                     | (dataframe["BMI_CAT"] == "Obese_Class2")
                     | (dataframe["BMI_CAT"] == "Obese_Class3")), "Life_Level_CAT"] = "At_Risk"

    dataframe['Life_Level_CAT'].fillna('Not_Risk', inplace = True)

featureExtraction(df)

drawOutliers(dfOriginal,"Original Data set")

drawOutliers(df,"Processed Data set")

def drawHistPlot(dataframe, title):
    a = 4
    b = 2
    c = 1
    colors=[]
    missing_cols = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
    palette_set2 = sns.color_palette("Paired",len(num_cols))
    for color in palette_set2.as_hex():
        colors.append(color)
    colour_num_cols = zip(missing_cols, colors)

    fig = plt.figure(figsize = (13, 15))
    for col, color in colour_num_cols:
        plt.subplot(a, b, c)
        sns.histplot(data=dataframe, x=col, kde=True, color=color);
        plt.xlabel(f'{dataframe[col].name}', size=15)
        c = c + 1
        plt.suptitle(title, size=18);

    plt.tight_layout()
    plt.subplots_adjust(hspace=0.25)
    plt.show()

drawHistPlot(dfOriginal,"Original Data set")

drawHistPlot(df,"Processed Data set")

fig,  axs = plt.subplots(1,2, figsize = (15, 5))

ax = sns.countplot(data=df,
                   x=df['Outcome'].replace({0: 'NEGATIVE', 1: 'POSITIVE'}),
                   ax = axs[0],
                   palette=["#ffcce7", "#81b7d2"]);

ax.set_xlabel('Outcome', fontsize=14)
ax.set_ylabel('Count', fontsize=14)
axs[0].set_title("Count of Diabetes", fontsize=16)

def func(pct, allvals):
    absolute = int(np.round(pct/100.*np.sum(allvals)))
    return f"{pct:.2f}%\n({absolute:d})"

ax2 = df['Outcome'].value_counts().plot.pie(explode=[0,0.07],
                                                 colors=["#81b7d2", "#ffcce7"],
                                                 autopct=lambda pct: func(pct, df['Outcome'].value_counts()),
                                                 ylabel='',
                                                 labels=['NEGATIVE', 'POSITIVE'],
                                                 ax = axs[1],
                                                 textprops=dict(color="black", size=13));
axs[1].set_title("Ratio of Diabetes", fontsize=16)

plt.tight_layout()
plt.show()

newCols = ["Insulin_CAT", "BloodPressure_CAT", "Glucose_CAT", "BMI_CAT"]

a = 2
b = 2
c = 1
fig = plt.figure(figsize = (15, 11))
for col in newCols:
    plt.subplot(a, b, c)
    ax = sns.countplot(df,
                       x=df[col],
                       hue=df.Outcome,
                       palette=["#AA96DA", "#C5FAD5"])
    plt.ylabel('Count')
    plt.xlabel(f'{col}', size=15)
    c = c + 1

plt.tight_layout()
plt.subplots_adjust(hspace=0.17)
plt.show()

"""**ML**"""

def oneHotEncoder(dataframe, categorical_col, drop_first=True):
    dataframe = pd.get_dummies(dataframe, columns=categorical_col, drop_first=drop_first)
    return dataframe

def labelEncoder(dataframe, binary_col):
    labelencoder = LabelEncoder()
    dataframe[binary_col] = labelencoder.fit_transform(dataframe[binary_col])
    return dataframe

def dataPrep(X, y):

    index = X.index
    dataframe = X.merge(y.to_frame(), left_index=True, right_index=True).set_index(index)

    # get cols
    cat_cols, num_cols, cat_but_car = getColNames(dataframe, print_results=False)

    # replace outliers
    [checkOutlier(dataframe, col) for col in num_cols]

    # Treat zero values as missing values after acquiring domain knowledge
    missing_value = ["Glucose", "BloodPressure", "SkinThickness", "Insulin", "BMI"]
    for col in missing_value:
        dataframe[col] = np.where(dataframe[col] == 0, np.nan, dataframe[col])
    dataframe = dataframe.fillna(dataframe.groupby('Outcome').transform('median'))

    # Feature Engineering
    featureExtraction(dataframe)

    # Scaling
    rs = RobustScaler()
    dataframe[num_cols] = rs.fit_transform(dataframe[num_cols])

    # binary encoding
    binary_cols = [col for col in dataframe.columns
                   if dataframe[col].dtype not in ["int64", "float64"]
                   and dataframe[col].nunique() == 2]
    for col in binary_cols:
        labelEncoder(dataframe, col)

    # One-hot-encoding
    ohe_cols = [col for col in dataframe.columns if 12 >= dataframe[col].nunique() > 2]
    dataframe = oneHotEncoder(dataframe, ohe_cols, drop_first=True)

    X = dataframe.drop(["Outcome"], axis=1)
    y = dataframe["Outcome"]
    return X, y

"""fitting original DF"""

X = df.drop(["Outcome"], axis=1)
y = df["Outcome"]
X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.20, random_state=42)

"""Defining model function"""

X_train, y_train = dataPrep(X_train, y_train)
X_test, y_test = dataPrep(X_test, y_test)

def base_models(X, y):
    models = [("Logistic Regression", LogisticRegression(solver='lbfgs', max_iter=3000)),
              ("Decision Tree Classifier", DecisionTreeClassifier()),
              ("Random Forest Classifier", RandomForestClassifier()),
              ("LGBM Classifier", LGBMClassifier()),]
    for name, classifier in models:
        cv_results = cross_validate(classifier, X, y, cv=5, scoring="accuracy")
        print(f"Accuracy: {round(cv_results['test_score'].mean(), 4)} ({name}) ")

cart_params = {'max_depth': range(1, 20),
               "min_samples_split": range(2, 30)}

rf_params = {"max_depth": [8, 15, None],
             "max_features": [5, 7],
             "min_samples_split": [15, 20],
             "n_estimators": [200, 300]}

lightgbm_params = {"learning_rate": [0.01, 0.1],
                   "n_estimators": [300, 500, 1500],
                   "colsample_bytree": [0.5, 0.7, 1]}

classifiers  =[("Decision Tree Classifier", DecisionTreeClassifier(), cart_params),
               ("Random Forest Classifier", RandomForestClassifier(), rf_params),
               ('LGBM Classifier', LGBMClassifier(), lightgbm_params)]

def hyperparameterOptimization(X, y, cv=5, scoring="accuracy"):
    print("\nHyperparameter Optimization....")
    best_models = {}
    for name, classifier, params in classifiers:
        print(f"------------------------------- {name} -------------------------------")
        cv_results = cross_validate(classifier, X, y, cv=cv, scoring=scoring)
        print(f"{scoring} (Before): {round(cv_results['test_score'].mean(), 4)}")

        gs_best = GridSearchCV(classifier, params, cv=cv, n_jobs=-1, verbose=False).fit(X, y)
        final_model = classifier.set_params(**gs_best.best_params_)

        cv_results = cross_validate(final_model, X, y, cv=cv, scoring=scoring)
        print(f"{scoring} (After): {round(cv_results['test_score'].mean(), 4)}")
        print(f"{name} best params: {gs_best.best_params_}", end="\n\n")
        best_models[name] = final_model
    return best_models

def votingClassifier(best_models, X, y):
    print("\nVoting Classifier...")
    voting_clf = VotingClassifier(estimators=[('Random Forest Classifier', best_models["Random Forest Classifier"]),
                                              ('LGBM Classifier', best_models["LGBM Classifier"])],
                                  voting='soft').fit(X, y)
    cv_results = cross_validate(voting_clf, X, y, cv=3, scoring=["accuracy", "f1", "roc_auc"])
    print(f"Accuracy: {cv_results['test_accuracy'].mean()}")
    print(f"F1Score: {cv_results['test_f1'].mean()}")
    print(f"ROC_AUC: {cv_results['test_roc_auc'].mean()}")
    return voting_clf

def fitModels(X,y):
    base_models(X, y)
    best_models = hyperparameterOptimization(X, y)
    voting_clf = votingClassifier(best_models, X, y)
    return voting_clf, best_models

voting_clf, best_models = fitModels(X_train, y_train)

lgbm_model = best_models['LGBM Classifier'].fit(X_train, y_train)

model_save_path = 'lgbm_Diabetes_classifier_model.txt'

# Save the trained model to the specified path

lgbm_model.booster_.save_model(model_save_path)

def plot_importance(model, features, num=len(X)):
    feature_imp = pd.DataFrame({'Value': model.feature_importances_,
                                'Feature': features.columns})
    plt.figure(figsize=(10, 10))
    sns.set(font_scale=1)
    sns.barplot(x="Value", y="Feature", data=feature_imp.sort_values(by="Value",
                                                                     ascending=False)[0:num])
    plt.title('Features')
    plt.tight_layout()
    plt.show()

plot_importance(lgbm_model, X_train)

y_pred = lgbm_model.predict(X_test)
y_prob = lgbm_model.predict_proba(X_test)[:, 1]
print(classification_report(y_test, y_pred))

lgbm_roc_auc = roc_auc_score(y_test, y_prob)
fpr, tpr, thresholds = roc_curve(y_test, y_prob)
plt.figure()

plt.plot([0,1],[0,1],'r--')
plt.plot(fpr, tpr, marker='.', label='LGBM')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title("LGBM ROC")
plt.legend()
plt.show()

cnf_matrix = confusion_matrix(y_test, y_pred)
p = sns.heatmap(pd.DataFrame(cnf_matrix ),
                annot=True,
                cmap="PuRd",
                annot_kws={"size": 16})
plt.title('Confusion matrix', size=14)
plt.ylabel('Actual', size=14)
plt.xlabel('Predicted', size=14);